import os
import re
import json
import time
import textwrap
from typing import List, Literal

import streamlit as st
from pydantic import BaseModel, Field, ValidationError
from PyPDF2 import PdfReader
from openai import OpenAI

# --- [æ–°å¢] å°å…¥ spaCy ---
import spacy

import Risk_Knowledge

# ---------------- UI CONFIG (must be the first Streamlit call) ----------------
st.set_page_config(page_title="Contract Risk Classifier", layout="wide")
st.logo("logo.png")

# ---------------- Configuration ----------------
MODEL_NAME = "gpt-4o"

# ---------------- Pydantic Schema ----------------
class ClauseRisk(BaseModel):
    clause: str
    risk: Literal["HIGH", "MEDIUM"]
    reason: str
    tags: List[str] = Field(default_factory=list)

RISK_RUBRIC = Risk_Knowledge.get_risk_rubric_string()
# ---------------- Prompts ----------------
SYSTEM_PROMPT = """
You are a contract risk analyst for a consulting firm.
Return a SINGLE JSON object with EXACT keys:
- clause: the clause text (string)
- risk: one of HIGH, MEDIUM (string, UPPERCASE)
- reason: <= 150 words (string)
- tags: short keywords (array of strings)

**Risk Classification Rubric:**
---
{RISK_RUBRIC}
---
Rules:
- Use the rubric
- Do NOT wrap in any extra key (e.g., no {"ClauseRisk": {...}}).
- Do NOT return a list.
- Do NOT include extra keys.
"""

# ---------------- Helpers ----------------
def extract_text_from_pdf(file) -> str:
    reader = PdfReader(file)
    return "\n".join((page.extract_text() or "") for page in reader.pages)

# --- [æ–°å¢] ä½¿ç”¨ spaCy è¼‰å…¥æ¨¡å‹ (å¿«å–ä»¥æé«˜æ•ˆèƒ½) ---
@st.cache_resource
def load_spacy_model():
    """è¼‰å…¥ spaCy æ¨¡å‹ä¸¦è™•ç†éŒ¯èª¤ã€‚"""
    try:
        return spacy.load("en_core_web_sm")
    except OSError:
        st.error("æ‰¾ä¸åˆ° spaCy æ¨¡å‹ 'en_core_web_sm'ã€‚è«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œ: python -m spacy download en_core_web_sm")
        return None

# --- [é‡å¤§ä¿®æ”¹] ä½¿ç”¨ spaCy é€²è¡Œæ›´ç²¾æº–çš„å¥å­/æ¢æ¬¾åˆ‡å‰² ---
def split_into_clauses_spacy(text: str) -> List[str]:
    """
    ä½¿ç”¨ spaCy é€²è¡Œèªæ„æ„ŸçŸ¥çš„å¥å­åˆ†å‰²ï¼Œä¸¦å°‡ç›¸é—œå¥å­çµ„åˆæˆæœ‰æ„ç¾©çš„æ¢æ¬¾ã€‚
    """
    nlp = load_spacy_model()
    if nlp is None:
        return []

    # é è™•ç†ï¼šå°‡å¤šå€‹æ›è¡Œç¬¦åˆä½µç‚ºä¸€å€‹ï¼Œä¸¦ç§»é™¤å¤šé¤˜çš„ç©ºç™½
    processed_text = re.sub(r'\n\s*\n', '\n', text)
    processed_text = re.sub(r' +', ' ', processed_text)

    doc = nlp(processed_text)
    clauses = []
    current_chunk = ""

    for sent in doc.sents:
        sentence_text = sent.text.strip()
        if not sentence_text:
            continue

        # æ ¸å¿ƒé‚è¼¯ï¼šå¦‚æœç•¶å‰ chunk åŠ ä¸Šæ–°å¥å­å¾Œä¸æœƒå¤ªé•·ï¼Œå°±åˆä½µ
        # å¦‚æœæ–°å¥å­çœ‹èµ·ä¾†åƒä¸€å€‹åˆ—è¡¨é …æˆ–æ–°æ®µè½çš„é–‹é ­ï¼Œå°±å¼·åˆ¶åˆ‡åˆ†
        is_list_item = re.match(r'^\(?[a-z0-9A-Z]\)|^\d+\.\s*|^[â€¢\-*]\s+', sentence_text)

        if current_chunk and (len(current_chunk) + len(sentence_text) > 1800 or is_list_item):
            # é•·åº¦è¶…éä¸Šé™æˆ–é‡åˆ°æ–°çš„åˆ—è¡¨é …ï¼Œå„²å­˜å‰ä¸€å€‹ chunk
            if len(current_chunk) > 80: # ç¢ºä¿ chunk æœ‰è¶³å¤ çš„å…§å®¹
                 clauses.append(current_chunk)
            current_chunk = sentence_text
        else:
            # åˆä½µå¥å­
            current_chunk += (" " + sentence_text)

    # åŠ å…¥æœ€å¾Œä¸€å€‹ chunk
    if current_chunk and len(current_chunk) > 80:
        clauses.append(current_chunk.strip())

    # å¦‚æœ spaCy åˆ‡å‰²å¾Œæ²’æœ‰çµæœ (å¯èƒ½æ–‡æœ¬å¤ªçŸ­)ï¼Œä½¿ç”¨åŸå§‹çš„æ­£å‰‡è¡¨é”å¼ä½œç‚ºå‚™æ´
    if not clauses:
        parts = re.split(r'\n\s*\n', text) # ç°¡æ˜“çš„æ®µè½åˆ‡å‰²
        clauses = [p.strip() for p in parts if 80 < len(p.strip()) < 1800]

    return clauses[:100] # ç¶­æŒæœ€å¤š100æ¢çš„é™åˆ¶

def normalize_model_json(raw: str, original_clause: str) -> dict:
    try:
        data = json.loads(raw)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", raw, flags=re.DOTALL)
        if not m:
            raise
        data = json.loads(m.group(0))

    if isinstance(data, dict) and "ClauseRisk" in data and isinstance(data["ClauseRisk"], dict):
        data = data["ClauseRisk"]

    if isinstance(data, list) and data and isinstance(data[0], dict):
        data = data[0]

    synonyms = {
        "riskLevel": "risk",
        "risk_level": "risk",
        "level": "risk",
        "label": "risk",
        "explanation": "reason",
        "rationale": "reason",
        "justification": "reason",
        "text": "clause",
        "content": "clause",
        "clause_text": "clause",
        "summary": "reason",
    }
    if isinstance(data, dict):
        for old, new in list(synonyms.items()):
            if old in data and new not in data:
                data[new] = data[old]
        risk_val = str(data.get("risk", "")).strip().upper()
        if risk_val not in ("HIGH", "MEDIUM"):
            risk_val = "MEDIUM"
        data["risk"] = risk_val
        data.setdefault("tags", [])
        data.setdefault("clause", original_clause)
    return data

def classify_clause(client: OpenAI, clause: str) -> ClauseRisk:
    user_prompt = f"Clause:\n{clause}\n\nReturn the JSON object now."
    resp = client.chat.completions.create(
        model=MODEL_NAME,
        temperature=0.1,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt},
        ],
        response_format={"type": "json_object"},
    )
    content = resp.choices[0].message.content
    normalized = normalize_model_json(content, original_clause=clause)
    return ClauseRisk.model_validate(normalized)

def classify_batch(clauses: List[str]) -> List[ClauseRisk]:
    client = OpenAI()
    out: List[ClauseRisk] = []
    for c in clauses:
        try:
            out.append(classify_clause(client, c))
        except ValidationError as ve:
            out.append(
                ClauseRisk(
                    clause=c,
                    risk="MEDIUM",
                    reason=f"Validation fallback: {ve.errors()[0]['type']}",
                    tags=["fallback"],
                )
            )
        except Exception as e:
            out.append(
                ClauseRisk(
                    clause=c,
                    risk="MEDIUM",
                    reason=f"Model error: {str(e)[:60]}",
                    tags=["error"],
                )
            )
        time.sleep(0.05)
    return out

# ---------------- App Header ----------------
st.header("åˆç´„é¢¨éšªè©•é‘‘ Contract Risk Classifier")
st.markdown("ä¸Šå‚³åˆç´„ PDF ä»¥æ¨™ç¤º**é«˜/ä¸­**é¢¨éšªæ¢æ¬¾ä¸¦é™„ä¸Šç°¡çŸ­èªªæ˜ã€‚")

# ---------------- Session State ----------------
if "results" not in st.session_state:
    st.session_state.results = []          # list of ClauseRisk
if "resolved" not in st.session_state:
    st.session_state.resolved = set()      # set of indices (ints)

# ---------------- Controls ----------------
left, right = st.columns([2, 1])

with left:
    uploaded = st.file_uploader("Upload a Contract (.pdf)", type=["pdf"], key="contract_pdf")
    process_clicked = st.button("è™•ç†ä¸Šå‚³ Process Upload", type="primary", use_container_width=True, disabled=uploaded is None)

with right:
    cap = st.number_input("æœ€å¤§å¯åˆ†æå­å¥æ•¸ Max Clauses to Analyze", min_value=5, max_value=100, value=30, step=5)
    model_name = st.text_input("é€²éšæ¨¡å‹ Model", value=MODEL_NAME)
    if model_name:
        MODEL_NAME = model_name

# ---------------- Process PDF ----------------
if process_clicked:
    if not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEY not set. Please set it in your environment.")
        st.stop()

    if uploaded is None:
        st.warning("Please choose a PDF first.")
        st.stop()

    # Extract & split
    text = extract_text_from_pdf(uploaded)
    # --- [ä¿®æ”¹] å‘¼å«æ–°çš„åˆ‡å‰²å‡½å¼ ---
    clauses = split_into_clauses_spacy(text)[:cap]
    st.caption(f"Found {len(clauses)} clause-like chunks.")

    with st.spinner("Classifying clausesâ€¦"):
        results = classify_batch(clauses)

    # Persist results and reset resolved flags
    st.session_state.results = results
    st.session_state.resolved = set()

# ---------------- Render Results ----------------
if st.session_state.results:
    results: List[ClauseRisk] = st.session_state.results
    resolved: set = st.session_state.resolved

    # Helpers for buttons (on_click: Streamlit auto-reruns)
    def mark_resolved(idx: int):
        st.session_state.resolved.add(idx)

    def undo_resolved(idx: int):
        st.session_state.resolved.discard(idx)

    def resolve_all():
        st.session_state.resolved = set(range(len(st.session_state.results)))

    def clear_resolved():
        st.session_state.resolved = set()

    # Compute active (unresolved) items and counts
    active_indices = [i for i in range(len(results)) if i not in resolved]
    active_results = [results[i] for i in active_indices]

    counts = {"HIGH": 0, "MEDIUM": 0}
    for r in active_results:
        counts[r.risk] += 1

    st.subheader("Summary")
    st.write(
        f"ğŸ”´ HIGH: **{counts['HIGH']}** Â·  ğŸŸ  MEDIUM: **{counts['MEDIUM']}** Â·  âœ… Resolved: **{len(resolved)}**"
    )
    st.divider()

    show_resolved = st.checkbox("Show resolved items", value=False)

    badge_map = {"HIGH": "ğŸ”´ HIGH RISK", "MEDIUM": "ğŸŸ  MEDIUM RISK"}

    def render_card(idx: int, item: ClauseRisk, is_resolved: bool):
        with st.container(border=True):
            left_col, right_col = st.columns([6, 1])
            with left_col:
                if is_resolved:
                    st.markdown(f"**âœ… RESOLVED** Â·  _{', '.join(item.tags) or 'untagged'}_")
                else:
                    st.markdown(f"**{badge_map[item.risk]}** Â·  _{', '.join(item.tags) or 'untagged'}_")
                st.write(textwrap.shorten(item.clause, 550))
                st.caption(item.reason)
            with right_col:
                if not is_resolved:
                    st.button(
                        "Resolved",
                        key=f"resolve_btn_{idx}",
                        help="Mark this clause as resolved (removes from counts and export)",
                        on_click=mark_resolved,
                        args=(idx,),
                        use_container_width=True,
                    )
                else:
                    st.button(
                        "Undo",
                        key=f"undo_btn_{idx}",
                        help="Restore this clause to the active list",
                        on_click=undo_resolved,
                        args=(idx,),
                        use_container_width=True,
                    )

    # Active (unresolved) first
    for i in active_indices:
        render_card(i, results[i], is_resolved=False)

    # Optionally show resolved items
    if show_resolved and len(resolved) > 0:
        st.markdown("### Resolved")
        for i in sorted(resolved):
            render_card(i, results[i], is_resolved=True)

    # ------------- Exports -------------
    st.markdown("â€”")

    # Default export: unresolved only (as TXT)
    export_payload = [results[i].model_dump() for i in range(len(results)) if i not in resolved]
    export_text = "\n\n".join(
    f"Clause: {r['clause']}\nRisk: {r['risk']}\nReason: {r['reason']}\nTags: {', '.join(r['tags']) or 'untagged'}"
    for r in export_payload
    )

    st.download_button(
        "Save TXT (Unresolved Only)",
        data=export_text.encode("utf-8"),
        file_name="risk_flags_unresolved.txt",
        mime="text/plain",
        use_container_width=True,
    )