import streamlit as st
import os
import tempfile
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
# å¾æˆ‘å€‘çš„å…±ç”¨å‡½å¼åº«ä¸­å°å…¥å‡½å¼
from utils import (
    extract_revisions_from_single_doc,
    extract_comments_from_docx,
    ingest_docs_to_pinecone,
    get_pinecone_client
)

st.set_page_config(page_title="ç®¡ç†å¾Œå°", page_icon="âš™ï¸", layout="wide")
# --- ã€ä¿®æ”¹ã€‘: ä½¿ç”¨ st.logo() ---
st.logo("logo.png")

st.header("çŸ¥è­˜åº«ç®¡ç†å¾Œå° Knowledge Base Admin Dashboard")
st.markdown("åœ¨é€™è£¡ï¼Œæ‚¨å¯ä»¥ç®¡ç† GCO ç¶“é©—æˆ–é€²è¡Œç³»çµ±ç¶­è­·ã€‚")

INDEX_NAME = "contract-assistant"


# --- åŠŸèƒ½ä¸€ï¼šä¸Šå‚³ GCO ç¶“é©—æ–‡ä»¶ ---
st.subheader("ä¸Šå‚³ GCO å¯©é–±ç¶“é©—æ–‡ä»¶ (.docx)")
gco_file = st.file_uploader("é¸æ“‡åŒ…å«è¿½è¹¤ä¿®è¨‚æˆ–è¨»è§£çš„ Word æª”æ¡ˆ", type="docx", key="gco_uploader")

gco_namespace = st.text_input(
    "ç‚ºé€™ä»½ GCO ç¶“é©—æŒ‡å®šä¸€å€‹ Namespace",
    value="gco-case-studies",
    help="å»ºè­°å°‡æ‰€æœ‰ GCO ç¶“é©—æ–‡ä»¶éƒ½å­˜å…¥åŒä¸€å€‹ Namespaceï¼Œæ–¹ä¾¿çµ±ä¸€æª¢ç´¢ã€‚"
)

if st.button("å¾ GCO æ–‡ä»¶æå–ä¸¦å„²å­˜ç¶“é©—"):
    if gco_file and gco_namespace:
        with st.spinner(f"æ­£åœ¨å¾ '{gco_file.name}' æå– GCO ç¶“é©—..."):
            with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp_file:
                tmp_file.write(gco_file.getvalue())
                tmp_file_path = tmp_file.name

            # æå–ç¶“é©—
            word_nsmap = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
            revision_chunks = extract_revisions_from_single_doc(tmp_file_path, word_nsmap)
            comment_chunks = extract_comments_from_docx(tmp_file_path)
            all_wisdom_chunks = revision_chunks + comment_chunks

            os.remove(tmp_file_path)

        if all_wisdom_chunks:
            # å°‡æå–å‡ºçš„ç¶“é©—æ–‡å­—è½‰æ›ç‚º LangChain Document ç‰©ä»¶
            with tempfile.NamedTemporaryFile(delete=False, mode="w+", encoding="utf-8") as wisdom_txt:
                wisdom_txt.write("\n".join(all_wisdom_chunks))
                wisdom_txt_path = wisdom_txt.name

            loader = TextLoader(wisdom_txt_path)
            documents = loader.load()

            # ä¸Šå‚³è‡³ Pinecone
            ingest_docs_to_pinecone(documents, INDEX_NAME, gco_namespace)
            os.remove(wisdom_txt_path)
            st.success(f"æˆåŠŸæå–ä¸¦å„²å­˜äº† {len(all_wisdom_chunks)} æ¢ GCO ç¶“é©—ï¼")
        else:
            st.warning("åœ¨æ–‡ä»¶ä¸­æœªæ‰¾åˆ°å¯æå–çš„è¿½è¹¤ä¿®è¨‚æˆ–è¨»è§£ã€‚")
    else:
        st.error("è«‹ä¸Šå‚³æª”æ¡ˆä¸¦æŒ‡å®š Namespaceã€‚")

st.divider()



# --- åŠŸèƒ½äºŒï¼šç´¢å¼•ç®¡ç† (å±éšªå€åŸŸ) ---
with st.expander("ğŸš¨ å±éšªå€åŸŸï¼šç´¢å¼•ç®¡ç†"):
    st.warning("è­¦å‘Šï¼šä»¥ä¸‹æ“ä½œå°‡æœƒæ°¸ä¹…åˆªé™¤çŸ¥è­˜åº«ä¸­çš„è³‡æ–™ã€‚")

    if st.button("æ¸…ç©ºç´¢å¼•å…§æ‰€æœ‰è³‡æ–™ (Delete All Vectors)"):
        try:
            pc = get_pinecone_client()
            index = pc.Index(INDEX_NAME)
            index.delete(delete_all=True)
            st.success(f"å·²æˆåŠŸæ¸…ç©ºç´¢å¼• '{INDEX_NAME}' ä¸­çš„æ‰€æœ‰è³‡æ–™ï¼")
            # æ¸…é™¤å¿«å–ï¼Œè®“ä¸»é çš„ä¸‹æ‹‰é¸å–®èƒ½æ„ŸçŸ¥åˆ°è®ŠåŒ–
            st.cache_data.clear()
        except Exception as e:
            st.error(f"æ¸…ç©ºç´¢å¼•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
