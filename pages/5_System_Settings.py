import streamlit as st
import os, boto3
import tempfile
from dotenv import load_dotenv
import os
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from text_splitter import recursive_split
# å¾å…±ç”¨å‡½å¼åº«ä¸­å°å…¥å‡½å¼
from utils import (
    extract_revisions_from_single_doc,
    extract_comments_from_docx,
    ingest_docs_to_pinecone,
    get_pinecone_client
)
load_dotenv()
st.set_page_config(page_title="ç®¡ç†å¾Œå°", page_icon="âš™ï¸", layout="wide")
# --- ã€ä¿®æ”¹ã€‘: ä½¿ç”¨ st.logo() ---
st.logo("logo.png")

st.header("çŸ¥è­˜åº«ç®¡ç†å¾Œå° Knowledge Base Admin Dashboard")
st.markdown("åœ¨é€™è£¡ï¼Œæ‚¨å¯ä»¥ç®¡ç† GCO ç¶“é©—æˆ–é€²è¡Œç³»çµ±ç¶­è­·ã€‚")

INDEX_NAME = "contract-assistant"

# å¾ S3 ingest èªå¯å ±å‘Š
from dotenv import load_dotenv
load_dotenv()

def ingest_reports_from_s3(bucket_name, prefix="", namespace="approved_reports"):
    s3 = boto3.client(
        's3',
        aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
        aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
        region_name=os.getenv("AWS_REGION_NAME")
    )
    objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
    if "Contents" not in objects:
        st.warning("âŒ S3 æ²’æœ‰æ‰¾åˆ°ä»»ä½•å ±å‘Š")
        return
    for obj in objects["Contents"]:
        key = obj["Key"]
        if not key.endswith(".md"):
            continue
        with tempfile.NamedTemporaryFile(delete=False, suffix=".md") as tmp:
            s3.download_fileobj(bucket_name, key, tmp)
            tmp_path = tmp.name

        loader = TextLoader(tmp_path, encoding="utf-8")
        docs = loader.load()

        if docs:
            splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=100
            )
            docs_split = splitter.split_documents(docs)
            ingest_docs_to_pinecone(
                docs_split,
                os.getenv("PINECONE_INDEX"),
                namespace
            )

        os.remove(tmp_path)
        st.success(f"âœ… å·²å­¸ç¿’å ±å‘Šï¼š{key}")



# --- åŠŸèƒ½ä¸€ï¼šä¸Šå‚³ GCO ç¶“é©—æ–‡ä»¶ ---
st.subheader("ä¸Šå‚³ GCO å¯©é–±ç¶“é©—æ–‡ä»¶ (.docx)")
gco_file = st.file_uploader("é¸æ“‡åŒ…å«è¿½è¹¤ä¿®è¨‚æˆ–è¨»è§£çš„ Word æª”æ¡ˆ", type="docx", key="gco_uploader")

gco_namespace = st.text_input(
    "ç‚ºé€™ä»½ GCO ç¶“é©—æŒ‡å®šä¸€å€‹ Namespace",
    value="gco-case-studies",
    help="å»ºè­°å°‡æ‰€æœ‰ GCO ç¶“é©—æ–‡ä»¶éƒ½å­˜å…¥åŒä¸€å€‹ Namespaceï¼Œæ–¹ä¾¿çµ±ä¸€æª¢ç´¢ã€‚"
)

if st.button("å¾ GCO æ–‡ä»¶æå–ä¸¦å„²å­˜ç¶“é©—"):
    if gco_file and gco_namespace:
        with st.spinner(f"æ­£åœ¨å¾ '{gco_file.name}' æå– GCO ç¶“é©—..."):
            with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp_file:
                tmp_file.write(gco_file.getvalue())
                tmp_file_path = tmp_file.name

            # æå–ç¶“é©—
            word_nsmap = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
            revision_chunks = extract_revisions_from_single_doc(tmp_file_path, word_nsmap)
            comment_chunks = extract_comments_from_docx(tmp_file_path)
            all_wisdom_chunks = revision_chunks + comment_chunks

            os.remove(tmp_file_path)

        if all_wisdom_chunks:
            # å°‡æå–å‡ºçš„ç¶“é©—æ–‡å­—è½‰æ›ç‚º LangChain Document ç‰©ä»¶
            with tempfile.NamedTemporaryFile(delete=False, mode="w+", encoding="utf-8") as wisdom_txt:
                wisdom_txt.write("\n".join(all_wisdom_chunks))
                wisdom_txt_path = wisdom_txt.name

            loader = TextLoader(wisdom_txt_path)
            documents = loader.load()

            # ä¸Šå‚³è‡³ Pinecone
            ingest_docs_to_pinecone(documents, INDEX_NAME, gco_namespace)
            os.remove(wisdom_txt_path)
            st.success(f"æˆåŠŸæå–ä¸¦å„²å­˜äº† {len(all_wisdom_chunks)} æ¢ GCO ç¶“é©—ï¼")
        else:
            st.warning("åœ¨æ–‡ä»¶ä¸­æœªæ‰¾åˆ°å¯æå–çš„è¿½è¹¤ä¿®è¨‚æˆ–è¨»è§£ã€‚")
    else:
        st.error("è«‹ä¸Šå‚³æª”æ¡ˆä¸¦æŒ‡å®š Namespaceã€‚")

st.divider()

st.subheader("ğŸ“š å ±å‘Šå­¸ç¿’ (S3)")
if st.button("é‡æ–°å­¸ç¿’ S3 å ±å‘Š"):
    bucket_name = st.secrets["aws"]["s3_bucket_name"]
    ingest_reports_from_s3(bucket_name)

# --- åŠŸèƒ½ä¸‰ï¼šç´¢å¼•ç®¡ç† (å±éšªå€åŸŸ) ---
with st.expander("ğŸš¨ å±éšªå€åŸŸï¼šç´¢å¼•ç®¡ç†"):
    st.warning("è­¦å‘Šï¼šä»¥ä¸‹æ“ä½œå°‡æœƒæ°¸ä¹…åˆªé™¤çŸ¥è­˜åº«ä¸­çš„è³‡æ–™ã€‚")

    if st.button("æ¸…ç©ºç´¢å¼•å…§æ‰€æœ‰è³‡æ–™ (Delete All Vectors)"):
        try:
            pc = get_pinecone_client()
            index = pc.Index(INDEX_NAME)
            index.delete(delete_all=True)
            st.success(f"å·²æˆåŠŸæ¸…ç©ºç´¢å¼• '{INDEX_NAME}' ä¸­çš„æ‰€æœ‰è³‡æ–™ï¼")
            # æ¸…é™¤å¿«å–ï¼Œè®“ä¸»é çš„ä¸‹æ‹‰é¸å–®èƒ½æ„ŸçŸ¥åˆ°è®ŠåŒ–
            st.cache_data.clear()
        except Exception as e:
            st.error(f"æ¸…ç©ºç´¢å¼•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
