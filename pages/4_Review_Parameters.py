import os
import tempfile
import streamlit as st
from datetime import datetime
from dotenv import load_dotenv

# LangChain / Vector DB
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain_community.vectorstores import FAISS
from langchain.retrievers.multi_query import MultiQueryRetriever

# --- [æ–°å¢] å°å…¥ S3 å„²å­˜èˆ‡ Pinecone å­¸ç¿’çš„å·¥å…·å‡½å¼åº« ---
import storage_utils as storage
from utils import ingest_docs_to_pinecone


# --- é é¢è¨­å®š ---
st.set_page_config(page_title="AI åˆç´„åˆå¯©", layout="wide", page_icon="ğŸ“")
st.logo("logo.png")


# --- ç’°å¢ƒè®Šæ•¸èˆ‡æ ¸å¿ƒè¨­å®š ---
load_dotenv()
# --- [æ–°å¢] AI å­¸ç¿’ç”¨çš„æ ¸å¿ƒè¨­å®š ---
LEARNING_NAMESPACE = "approved-analyses"
INDEX_NAME = "contract-assistant"

# --- ã€æ–°å¢ã€‘åˆå§‹åŒ–æ¨¡å‹åƒæ•¸çš„ Session State ---
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.3 # å»ºè­°çš„é è¨­å€¼
if "max_tokens" not in st.session_state:
    st.session_state.max_tokens = 3072 # å»ºè­°çš„é è¨­å€¼ï¼Œå› ç‚ºè©³ç´°å ±å‘Šéœ€è¦è¼ƒå¤šç©ºé–“

# -----------------------------
# Helpers
# -----------------------------

@st.cache_data(show_spinner=False)
def get_language(text_snippet: str, _llm):
    """ä½¿ç”¨ LLM å¿«é€Ÿæª¢æ¸¬æ–‡å­—èªè¨€"""
    if not text_snippet.strip():
        return "unknown"
    try:
        prompt = PromptTemplate.from_template("Detect the primary language of the following text. Respond with only the two-letter ISO 639-1 code (e.g., 'en' for English, 'zh' for Chinese). Text: ```{text}```")
        chain = prompt | _llm | StrOutputParser()
        sample = text_snippet[:200]
        lang_code = chain.invoke({"text": sample})
        return lang_code.lower()
    except Exception:
        return "unknown"

@st.cache_data(show_spinner=False)
def translate_to_chinese(text_to_translate: str, _llm):
    """ä½¿ç”¨ LLM å°‡æ–‡å­—ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡"""
    if not text_to_translate.strip():
        return ""
    try:
        prompt = PromptTemplate.from_template("Please translate the following legal text into Traditional Chinese. Only return the translated text, without any explanation or preamble. Text: ```{text}```")
        chain = prompt | _llm | StrOutputParser()
        return chain.invoke({"text": text_to_translate})
    except Exception as e:
        st.markdown(f"<span style='color:white'>ç¿»è­¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}</span>", unsafe_allow_html=True)
        return text_to_translate

# --- [MODIFIED] æ ¸å¿ƒæ¯”å°å‡½å¼å·²å®Œå…¨é‡æ§‹ ---
def run_comparison(template_retriever, uploaded_retriever, review_points, temperature, max_tokens):
    """
    åŸ·è¡Œåˆç´„æ¯”å°ï¼Œæ¡ç”¨ã€Œå…ˆåˆ†æã€å¾Œæ‘˜è¦ã€çš„å…©æ­¥é©Ÿé«˜å“è³ªç”Ÿæˆæµç¨‹ã€‚
    """
    llm = ChatOpenAI(model_name='gpt-4o', temperature=temperature, max_tokens=max_tokens)
    
    # --- STEP 1: å„ªåŒ–å¾Œçš„é«˜å“è³ªè©³ç´°å ±å‘Š Prompt ---
    # é€™å€‹ Prompt æ˜¯æ•´å€‹åˆ†æçš„æ ¸å¿ƒï¼Œå°ˆæ³¨æ–¼ç”¢ç”Ÿå…·æœ‰å•†æ¥­æ´å¯Ÿçš„æ·±åº¦åˆ†æã€‚
    tpl = """
**Role:** You are a seasoned Senior Legal Counsel at EY. Your primary duty is to protect EY's interests. Your review must be commercially-aware, risk-focused, and provide immediately actionable advice for our internal non-lawyer project teams.

**Objective:** Conduct a detailed preliminary review of a counterparty's contract clause ("Clause B") against our standard template ("Clause A") on the specific topic of "**{topic}**". Assume "Our Company" is EY.

---
**Context 1: Past High-Quality Analysis Examples (for style and depth reference)**
```{approved_examples}```
---
**Context 2: Clause A (Our Company's Standard Template - Normalized to Traditional Chinese)**
```{clause_A}```
---
**Context 3: Clause B (Counterparty's Draft - Normalized to Traditional Chinese)**
```{clause_B}```
---

**Task & Formatting Rules:**
1.  **Language:** The entire report MUST be written in the language of original clause.
2.  **Headings:** Use Markdown level 3 headings (`###`) for the two main sections (e.g., `### 1. æ ¸å¿ƒå·®ç•°èˆ‡å°æˆ‘æ–¹ (EY) çš„é¢¨éšª`).
3.  **Bullet Points:** Use a single dash (`- `) for all bullet points. Do not use asterisks (`*`) or circles (`o`).
4.  **Content:** Address all points with insightful, concise analysis based on the provided clauses.

### 1. æ ¸å¿ƒå·®ç•°èˆ‡å°æˆ‘æ–¹ (EY) çš„é¢¨éšª (Key Differences & Risks to EY)
-   **æ ¸å¿ƒå·®ç•°é» (Material Differences)**: Directly compare Clause A and B. Instead of just listing facts, synthesize the differences.
    * *Good Example:* `å°æ–¹è‰æ¡ˆå°‡ä¿å¯†ç¾©å‹™å»¶é•·è‡³åˆç´„çµ‚æ­¢å¾Œ5å¹´ï¼Œè€Œæˆ‘æ–¹ç¯„æœ¬åƒ…ç‚º2å¹´ï¼Œå¤§å¹…å¢åŠ äº†æˆ‘æ–¹é•·æœŸçš„æ³•å¾‹éµå¾ªæˆæœ¬èˆ‡é¢¨éšªã€‚`
    * *Bad Example:* `æ¢æ¬¾Aæ˜¯2å¹´ï¼Œæ¢æ¬¾Bæ˜¯5å¹´ã€‚`
-   **å° EY çš„æ½›åœ¨é¢¨éšª (Potential Risks to EY)**: For each key difference, explicitly state the commercial, legal, or operational risk. Frame it as "é€™å°‡ä½¿æˆ‘æ–¹é¢è‡¨...çš„é¢¨éšª" (This exposes us to the risk of...). Be specific to EY's business model (e.g., regulatory duties, data handling, global firm structure).

### 2. ä¿®è¨‚èˆ‡è«‡åˆ¤ç­–ç•¥å»ºè­° (Revision & Negotiation Strategy)
-   **é¦–é¸ä¿®è¨‚å»ºè­° (Primary Redline Suggestion)**: Provide a direct, copy-pasteable revision to Clause B to mitigate the risks. If no change is truly needed, state "å»ºè­°æ¥å— (Acceptable as is)".
-   **è«‡åˆ¤ç­–ç•¥èˆ‡åº•ç·š (Negotiation Strategy & Bottom Line)**:
    * **è«‡åˆ¤ç›®æ¨™ (Goal):** Clearly state our main goal (e.g., "ä¸»è¦ç›®æ¨™æ˜¯å°‡ä¿å¯†æœŸé™ç¸®çŸ­è‡³ä¸è¶…é3å¹´").
    * **ç†ç”±é—¡è¿° (Rationale):** Provide a brief, commercially-sound reason we can use in negotiations (e.g., "å‘å°æ–¹èªªæ˜ï¼Œ2-3å¹´æ˜¯è¡Œæ¥­æ¨™æº–ï¼Œéé•·çš„æœŸé™ä¸ç¬¦åˆæ¯”ä¾‹åŸå‰‡ä¸”å¢åŠ é›™æ–¹ç®¡ç†æˆæœ¬").
    * **å¾Œå‚™æ–¹æ¡ˆ (Fallback Position):** Offer a potential compromise if our primary suggestion is rejected (e.g., "è‹¥å°æ–¹å …æŒ5å¹´ï¼Œæˆ‘æ–¹å¯æ¥å—ï¼Œä½†è¦æ±‚å¢åŠ ã€ä¸åŒ…å«æˆ‘æ–¹ç‚ºéµå¾ªæ³•è¦æˆ–å°ˆæ¥­æº–å‰‡è€Œå¿…é ˆä¿ç•™çš„è³‡æ–™ã€ä¹‹è±å…æ¢æ¬¾").
"""
    analysis_chain = PromptTemplate.from_template(tpl) | llm | StrOutputParser()
    
    detailed_results = {}
    progress = st.progress(0, text="AI æ³•å‹™å°ˆå®¶æ­£åœ¨æ·±åº¦å¯©é–±åˆç´„...")

    mq_template_retriever = MultiQueryRetriever.from_llm(retriever=template_retriever, llm=llm)
    mq_uploaded_retriever = MultiQueryRetriever.from_llm(retriever=uploaded_retriever, llm=llm)
    
    # --- åŸ·è¡Œè©³ç´°åˆ†æçš„è¿´åœˆ ---
    for i, topic in enumerate(review_points):
        display_topic = topic.split(' (')[0].replace('&nbsp;', ' ').strip()
        search_query = topic.replace('&nbsp;', ' ')
        progress.progress((i + 0.5) / len(review_points), text=f"æ­£åœ¨æ·±åº¦åˆ†æ: {display_topic}")

        # --- [å„ªåŒ–å»ºè­°] å•Ÿå‹• Few-Shot Learning ---
        # é€™è£¡å¯ä»¥åŠ å…¥é‚è¼¯ï¼Œå¾ Pinecone çš„ LEARNING_NAMESPACE ä¸­æª¢ç´¢èˆ‡ topic ç›¸é—œçš„å„ªè‰¯ç¯„ä¾‹
        # a_text = search_for_approved_examples(topic) 
        # ç›®å‰æš«æ™‚ç¶­æŒåŸæ¨£
        a_text = "ç„¡ç›¸é—œç¯„ä¾‹"

        t_docs = mq_template_retriever.get_relevant_documents(search_query)
        u_docs = mq_uploaded_retriever.get_relevant_documents(search_query)
        
        t_text_original = "\n---\n".join([d.page_content for d in t_docs])
        u_text_original = "\n---\n".join([d.page_content for d in u_docs])
        
        lang_t = get_language(t_text_original, llm)
        lang_u = get_language(u_text_original, llm)
        
        with st.spinner(f"æ­£åœ¨é€²è¡Œèªè¨€æ­£è¦åŒ– ({display_topic})..."):
            t_text_final = translate_to_chinese(t_text_original, llm) if 'en' in lang_t else t_text_original
            u_text_final = translate_to_chinese(u_text_original, llm) if 'en' in lang_u else u_text_original

        if not t_text_final.strip(): t_text_final = "æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ç›¸é—œæ¢æ¬¾"
        if not u_text_final.strip(): u_text_final = "æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ç›¸é—œæ¢æ¬¾"
            
        report = analysis_chain.invoke({
            "topic": display_topic,
            "approved_examples": a_text,
            "clause_A": t_text_final,
            "clause_B": u_text_final
        })
        detailed_results[topic] = report
        
    # --- STEP 2: [NEW] åœ¨æ‰€æœ‰è©³ç´°å ±å‘Šç”Ÿæˆå¾Œï¼Œé€²è¡Œé«˜å“è³ªæ‘˜è¦ ---
    progress.progress(1.0, text="æ­£åœ¨æç…‰é¢¨éšªæ‘˜è¦ç¸½è¦½...")

    full_detailed_report_context = "\n\n---\n\n".join(
        f"### å¯©æŸ¥é …ç›®ï¼š{topic.split(' (')[0]}\n\n{report}" 
        for topic, report in detailed_results.items()
    )

    # æ–°çš„ã€å°ˆé–€ç”¨æ–¼å¾é«˜å“è³ªå ±å‘Šä¸­ç”Ÿæˆæ‘˜è¦çš„ Prompt
    final_summary_tpl = """
    ä½ æ˜¯ä¸€ä½é ‚å°–çš„æ³•å‹™å”ç†ï¼Œä½ çš„ä»»å‹™æ˜¯é–±è®€ä¸‹æ–¹çš„ã€Œé€é …å¯©é–±å ±å‘Šå…¨æ–‡ã€ï¼Œä¸¦ç‚ºé«˜éšä¸»ç®¡è£½ä½œä¸€ä»½æ¥µåº¦ç²¾ç°¡çš„ã€Œé¢¨éšªæ‘˜è¦ç¸½è¦½ã€ã€‚

    **ä»»å‹™æŒ‡ç¤º:**
    1.  **å°ˆæ³¨æ–¼æ ¸å¿ƒ**: å¾æ¯ä¸€é …å ±å‘Šä¸­ï¼Œæç…‰å‡ºæœ€é‡è¦çš„ã€Œæ ¸å¿ƒå·®ç•°èˆ‡é¢¨éšªã€ä»¥åŠæœ€é—œéµçš„ã€Œé¦–é¸ä¿®è¨‚å»ºè­°ã€ã€‚
    2.  **çµæœå°å‘**: æ‘˜è¦æ‡‰æ¸…æ™°ã€ç›´æ¥ï¼Œè®“è®€è€…èƒ½ç«‹åˆ»æŒæ¡å•é¡Œå’Œè§£æ±ºæ–¹æ¡ˆã€‚
    3.  **åš´æ ¼æ ¼å¼**: ä½ çš„å›ç­”ã€Œåªèƒ½ã€æ˜¯ä¸€è¡Œæ–‡å­—ã€‚ä½¿ç”¨ '|||' åˆ†éš”ã€Œä¸»é¡Œã€ã€ã€Œä¸»è¦å·®ç•°èˆ‡é¢¨éšªã€èˆ‡ã€Œæ ¸å¿ƒä¿®æ”¹å»ºè­°ã€ã€‚ä½¿ç”¨ ';;;' åˆ†éš”ä¸åŒçš„å¯©æŸ¥é …ç›®ã€‚åœ¨æ¯å€‹æ¬„ä½å…§éƒ¨ï¼Œä½ å¯ä»¥ä½¿ç”¨ Markdown çš„é»åˆ—å¼èªæ³• (`- `) èˆ‡æ›è¡Œ (`\\n`)ã€‚

    **æ ¼å¼ç¯„ä¾‹:**
    `åˆç´„çš„ä¿å¯†æœŸé™|||- å°æ–¹è‰æ¡ˆçš„ä¿å¯†æœŸé•·é”5å¹´ï¼Œå¤§å¹…å¢åŠ æˆ‘æ–¹é•·æœŸéµå¾ªé¢¨éšªã€‚\\n- èµ·ç®—é»ç‚ºåˆç´„çµ‚æ­¢å¾Œï¼Œå°æˆ‘æ–¹ä¸åˆ©ã€‚|||- å»ºè­°å°‡æœŸé™ç¸®çŸ­ç‚º EY æ¨™æº–çš„2å¹´ã€‚\\n- å»ºè­°ä¿®æ”¹èµ·ç®—é»ç‚ºã€Œè³‡è¨Šæ­éœ²æ—¥ã€ã€‚;;;æ©Ÿå¯†è³‡è¨Šçš„å®šç¾©ç¯„åœ|||- å°æ–¹å®šç¾©éæ–¼å¯¬æ³›ï¼Œå¯èƒ½å°‡å…¬é–‹è³‡è¨Šä¹Ÿç´å…¥ã€‚|||- å»ºè­°åŠ å…¥æˆ‘æ–¹ç¯„æœ¬ä¸­çš„äº”å¤§æ¨™æº–ä¾‹å¤–æƒ…æ³ã€‚`

    ---
    **é€é …å¯©é–±å ±å‘Šå…¨æ–‡:**
    ```{full_report}```
    ---
    **è«‹ç«‹å³ç”¢ç”Ÿç¬¦åˆä¸Šè¿°æ‰€æœ‰è¦æ±‚çš„æ‘˜è¦å…§å®¹:**
    """
    final_summary_prompt = PromptTemplate.from_template(final_summary_tpl)
    # ä½¿ç”¨ä¸€å€‹æº«åº¦è¼ƒä½çš„ç¨ç«‹ LLM ä¾†ç¢ºä¿æ‘˜è¦çš„ç©©å®šæ€§
    summary_llm = ChatOpenAI(model_name='gpt-4o', temperature=0.1, max_tokens=2048)
    summary_chain = final_summary_prompt | summary_llm | StrOutputParser()
    
    summary_raw = summary_chain.invoke({"full_report": full_detailed_report_context})
    
    # è§£ææ–°æ ¼å¼çš„æ‘˜è¦
    summary_points = []
    try:
        items = summary_raw.strip().split(';;;')
        for item in items:
            if not item.strip(): continue
            parts = item.strip().split('|||')
            if len(parts) == 3:
                topic, difference, suggestion = [p.strip().replace('\\n', '\n') for p in parts]
                summary_points.append({
                    'topic': topic,
                    'difference': difference,
                    'suggestion': suggestion
                })
            else: # å¦‚æœæ ¼å¼ä¸ç¬¦ï¼Œåšå€‹ç°¡å–®çš„é™ç´šè™•ç†
                 summary_points.append({'topic': item, 'difference': 'æ ¼å¼è§£æå¤±æ•—', 'suggestion': 'è«‹æŸ¥çœ‹è©³ç´°å ±å‘Š'})
    except Exception as e:
        st.error(f"ç”Ÿæˆæ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        summary_points.append({'topic': 'æ‘˜è¦ç”Ÿæˆå¤±æ•—', 'difference': 'ç„¡æ³•è§£æ AI å›æ‡‰', 'suggestion': str(e)})

    progress.empty()
    return {"summary": summary_points, "details": detailed_results}

@st.cache_resource
def load_and_process_pdf_for_faiss(_uploaded_file):
    if not _uploaded_file:
        return None
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(_uploaded_file.getvalue())
        path = tmp.name
    loader = PyPDFLoader(path)
    documents = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    split_docs = splitter.split_documents(documents)
    if not split_docs:
        os.remove(path)
        st.info(f"æ–‡ä»¶ '{_uploaded_file.name}' ä¸­æ²’æœ‰å¯è™•ç†çš„æ–‡å­—å…§å®¹ã€‚")
        return None
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vs = FAISS.from_documents(split_docs, embeddings)
    os.remove(path)
    return vs.as_retriever(search_kwargs={'k': 3})

def process_and_store_reference_file(uploaded_file):
    filename = uploaded_file.name
    with st.spinner(f"æ­£åœ¨è™•ç†åƒè€ƒæ–‡ä»¶ '{filename}' ä¸¦è¼‰å…¥è¨˜æ†¶é«”..."):
        retriever = load_and_process_pdf_for_faiss(uploaded_file)
        if retriever:
            st.session_state.reference_retrievers[filename] = retriever
            st.success(f"åƒè€ƒæ–‡ä»¶ '{filename}' å·²æˆåŠŸè¼‰å…¥ï¼")

# --- UI éƒ¨åˆ† (ç¶­æŒä¸è®Š) ---

if "reference_retrievers" not in st.session_state:
    st.session_state.reference_retrievers = {}

st.header("AI åˆç´„åˆå¯©èˆ‡é¢¨éšªåˆ†æ AI-Assisted Contract Preliminary Review and Risk Analysis")

CORE_REVIEW_POINTS = [
    "åˆç´„çš„ä¿å¯†æœŸé™ &nbsp;(Confidentiality Period)",
    "æ©Ÿå¯†è³‡è¨Šçš„å®šç¾©ç¯„åœ &nbsp;(Definition of Confidential Information)",
    "å…è¨±æ­éœ²æ©Ÿå¯†è³‡è¨Šçš„ä¾‹å¤–æƒ…æ³ &nbsp;(Permitted Disclosures)",
    "åˆç´„çš„æº–æ“šæ³•èˆ‡ç®¡è½„æ³•é™¢ &nbsp;(Governing Law and Jurisdiction)",
    "è³‡è¨Šè¿”é‚„æˆ–éŠ·æ¯€çš„ç¾©å‹™ &nbsp;(Return or Destruction of Information)",
    "é‡å°é•ç´„è¡Œç‚ºçš„è£œæ•‘æªæ–½æˆ–è³ å„Ÿæ¢æ¬¾ &nbsp;(Remedies for Breach)",
    "æ™ºæ…§è²¡ç”¢æ¬Šçš„æ­¸å±¬ &nbsp;(Intellectual Property Rights)",
    "é•ç´„é€šçŸ¥èˆ‡æ”¹å–„æœŸé™ &nbsp;(Notice of Breach and Cure Period)"
]
with st.expander("è‡ªè¨‚å¯©æŸ¥é …ç›® Customize Review Parameters", expanded=True):
    cols = st.columns(2)
    for i, point in enumerate(CORE_REVIEW_POINTS):
        with cols[i % 2]:
            st.toggle(point.split(" (")[0], value=True, key=point)
    st.text_area("æ–°å¢å¯©æŸ¥é …ç›®ï¼ˆæ¯è¡Œä¸€å€‹)ï¼š", key="core_points_text", height=100, placeholder="ä¾‹å¦‚ï¼š\nè³ å„Ÿè²¬ä»»ä¸Šé™ (Limitation of Liability)\nåˆç´„çš„å¯è½‰è®“æ€§ (Assignability)")
st.divider()

col1, col2 = st.columns(2)
with col1:
    st.header("æ­¥é©Ÿä¸€ï¼šä¸Šå‚³åƒè€ƒæ–‡ä»¶")
    new_ref_file = st.file_uploader("ä¸Šå‚³ PDF ä½œç‚ºæ–°çš„æ¯”å°åŸºæº–", type="pdf", key="ref_uploader_faiss")
    if st.button("è™•ç†ä¸¦è¼‰å…¥åƒè€ƒæ–‡ä»¶"):
        if new_ref_file:
            process_and_store_reference_file(new_ref_file)
        else:
            st.info("è«‹å…ˆé¸æ“‡ä¸€å€‹åƒè€ƒæ–‡ä»¶ã€‚")
with col2:
    st.header("æ­¥é©ŸäºŒï¼šé¸æ“‡æ¯”å°åŸºæº–")
    processed_files = list(st.session_state.reference_retrievers.keys())
    selected_index = None
    if st.session_state.get("selected_namespace") in processed_files:
        selected_index = processed_files.index(st.session_state.get("selected_namespace"))
    selected = st.selectbox(
        "å¾å·²ä¸Šå‚³çš„åƒè€ƒæ–‡ä»¶ä¸­é¸æ“‡ä¸€ä»½ï¼š",
        options=processed_files,
        index=selected_index,
        placeholder="è«‹é¸æ“‡..."
    )
    if selected is not None: 
        st.session_state.selected_namespace = selected
st.divider()

st.header("æ­¥é©Ÿä¸‰ï¼šè¨­å®š AI åˆ†æåƒæ•¸")
st.session_state.temperature = st.slider(
    "åƒæ•¸æº«åº¦ Temperature", 0.0, 1.0, st.session_state.temperature, 0.05,
    help='æ•¸å€¼è¼ƒä½ï¼Œçµæœæœƒæ›´å…·é«”å’Œä¸€è‡´ï¼›æ•¸å€¼è¼ƒé«˜ï¼Œçµæœæœƒæ›´æœ‰å‰µæ„å’Œå¤šæ¨£æ€§ã€‚å»ºè­°ä½¿ç”¨ 0.1-0.4 ä¹‹é–“çš„å€¼ä»¥ç²å¾—ç©©å®šä¸”å…·æ´å¯Ÿçš„åˆ†æã€‚'
)
st.session_state.max_tokens = st.slider(
    "æœ€å¤§å­—å…ƒæ•¸ Max Tokens", 512, 4096, st.session_state.max_tokens, 128,
    help='é™åˆ¶å–®æ¬¡ AI å›æ‡‰çš„é•·åº¦ã€‚ç”±æ–¼è©³ç´°å ±å‘Šå…§å®¹è¼ƒå¤šï¼Œå»ºè­°è¨­å®šåœ¨ 3000 ä»¥ä¸Šä»¥é¿å…å ±å‘Šè¢«æˆªæ–·ã€‚'
)
st.divider()

st.header("æ­¥é©Ÿå››ï¼šä¸Šå‚³å¾…å¯©æ–‡ä»¶ä¸¦åŸ·è¡Œåˆ†æ")
selected_namespace = st.session_state.get("selected_namespace")
if not selected_namespace:
    st.info("è«‹åœ¨ä¸Šæ–¹æ­¥é©Ÿä¸€ä¸Šå‚³åƒè€ƒæ–‡ä»¶ï¼Œä¸¦åœ¨æ­¥é©ŸäºŒé¸æ“‡ä¸€ä»½ä½œç‚ºæ¯”å°åŸºæº–ã€‚")
else:
    st.success(f"ç•¶å‰æ¯”å°åŸºæº–ç‚ºï¼š **{selected_namespace}**")

target_file = st.file_uploader("ä¸Šå‚³æ‚¨è¦å¯©æŸ¥çš„åˆç´„æ–‡ä»¶", type="pdf", key="target_uploader")

if target_file: 
    st.session_state.target_file_name = target_file.name

start_button = st.button("é–‹å§‹ AI æ·±åº¦å¯©é–±", type="primary", use_container_width=True, disabled=(not target_file or not selected_namespace))

if start_button:
    with st.spinner("æ­£åœ¨æº–å‚™æ¯”å°ç’°å¢ƒ..."):
        template_retriever = st.session_state.reference_retrievers[selected_namespace]
        uploaded_retriever = load_and_process_pdf_for_faiss(target_file)
        
    if not uploaded_retriever:
        st.info("å¾…å¯©æ–‡ä»¶è™•ç†å¤±æ•—æˆ–å…§å®¹ç‚ºç©ºï¼Œè«‹é‡æ–°ä¸Šå‚³ã€‚")
    else:
        temp = st.session_state.temperature
        max_tok = st.session_state.max_tokens
        
        active_review_points = [p for p in CORE_REVIEW_POINTS if st.session_state.get(p, True)]
        custom_points = [line.strip() for line in st.session_state.get("core_points_text", "").split('\n') if line.strip()]
        final_review_points = active_review_points + custom_points

        if not final_review_points:
            st.info("è«‹è‡³å°‘é¸æ“‡æˆ–æ–°å¢ä¸€å€‹å¯©æŸ¥é …ç›®ã€‚")
        else:
            st.session_state.comparison_results = run_comparison(template_retriever, uploaded_retriever, final_review_points, temp, max_tok)
            st.rerun()

# --- å ±å‘Šé¡¯ç¤ºèˆ‡å„²å­˜åŠŸèƒ½ (ç¶­æŒä¸è®Š) ---
if st.session_state.get("comparison_results"):
    st.balloons()
    st.header("âœ… AI æ·±åº¦å¯©é–±å ±å‘Šå·²å®Œæˆ")
    st.info("æ‚¨å¯ä»¥æª¢è¦–ä¸‹æ–¹çš„æ‘˜è¦èˆ‡å ±å‘Šï¼Œè‹¥æ‚¨èªç‚ºé€™ä»½å ±å‘Šå“è³ªå„ªè‰¯ï¼Œå¯å°‡å…¶æ­¸æª”ç”¨æ–¼ AI å†å­¸ç¿’ã€‚")
    st.divider()

    st.subheader("é¢¨éšªæ‘˜è¦ç¸½è¦½")
    
    summary_data = st.session_state.comparison_results.get('summary', [])
    details_data = st.session_state.comparison_results.get('details', {})

    full_report_md = "# AI åˆç´„å¯©é–±å ±å‘Š\n\n"
    
    summary_table_md = "| **é …ç›®** | **ä¸»è¦å·®ç•°èˆ‡é¢¨éšª** | **æ ¸å¿ƒä¿®æ”¹å»ºè­°** |\n"
    summary_table_md += "|:---|:---|:---|\n"
    for item in summary_data:
        # ç‚ºäº†é¡¯ç¤ºå’Œå„²å­˜ï¼Œæˆ‘å€‘éœ€è¦è™•ç†æ›è¡Œ
        topic_display = item.get('topic', 'N/A')
        difference_display = item.get('difference', '').replace('\n', '<br>')
        suggestion_display = item.get('suggestion', '').replace('\n', '<br>')
        summary_table_md += f"| {topic_display} | {difference_display} | {suggestion_display} |\n"
    
    st.markdown(summary_table_md, unsafe_allow_html=True)
    full_report_md += "## é¢¨éšªæ‘˜è¦ç¸½è¦½\n\n" + summary_table_md.replace('<br>', '\n') + "\n\n"
    st.divider()
    
    st.subheader("é€é …å¯©é–±å ±å‘Š")
    full_report_md += "## é€é …å¯©é–±å ±å‘Š\n\n"
    for topic, report_md in details_data.items():
        display_topic = topic.split(' (')[0].replace('&nbsp;', ' ').strip()
        with st.expander(f"**å¯©æŸ¥é …ç›®ï¼š{display_topic}**", expanded=False):
            st.markdown(report_md, unsafe_allow_html=True)
        full_report_md += f"### å¯©æŸ¥é …ç›®ï¼š{display_topic}\n\n{report_md}\n\n---\n\n"
        
    st.divider()
    
    st.subheader("ğŸ§  åˆ†ææ­¸æª”èˆ‡ AI å†å­¸ç¿’")
    st.markdown("è‹¥æ‚¨èªå¯é€™ä»½å ±å‘Šçš„åˆ†æå“è³ªï¼Œå¯ä»¥é»æ“Šä¸‹æ–¹æŒ‰éˆ•ï¼Œç³»çµ±æœƒå°‡å…¶æ­¸æª”è‡³ Amazon S3ï¼Œä¸¦å°‡å…¶å…§å®¹ä½œç‚ºä¸€å€‹å®Œæ•´çš„ã€Œå„ªè‰¯ç¯„ä¾‹ã€é¤µçµ¦ AI é€²è¡Œå­¸ç¿’ã€‚")

    if st.button("âœ… æˆ‘èªå¯é€™ä»½å ±å‘Šçš„å“è³ªï¼Œæ­¸æª”è‡³é›²ç«¯ä¸¦ç”¨æ–¼ AI å­¸ç¿’", type="primary", use_container_width=True):
        template_name = st.session_state.get("selected_namespace", "template").replace('.pdf', '')
        target_name = st.session_state.get("target_file_name", "target").replace('.pdf', '')
        timestamp = datetime.now().strftime('%Y%m%d')
        
        storage_filename = f"Approved_Report_{template_name}_vs_{target_name}_{timestamp}.md"
        
        upload_success = storage.upload_report_to_storage(full_report_md, filename=storage_filename)

        if upload_success:
            try:
                with st.spinner(f"æ­£åœ¨å°‡å ±å‘ŠçŸ¥è­˜è½‰åŒ–ç‚º AI çš„é•·æœŸè¨˜æ†¶..."):
                    learning_content = f"ã€å„ªè‰¯åˆ†ææ¡ˆä¾‹ï¼šåˆç´„å¯©é–±å ±å‘Š - {template_name} vs {target_name}ã€‘\n\n{full_report_md}"
                    
                    with tempfile.NamedTemporaryFile(delete=False, mode="w+", encoding="utf-8", suffix=".txt") as tmp_file:
                        tmp_file.write(learning_content)
                        tmp_file_path = tmp_file.name
                    
                    loader = TextLoader(tmp_file_path)
                    documents = loader.load()
                    ingest_docs_to_pinecone(documents, INDEX_NAME, LEARNING_NAMESPACE)
                    os.remove(tmp_file_path)
                    
                    st.success(f"AI å·²æˆåŠŸå­¸ç¿’æ­¤ä»½å ±å‘Šçš„åˆ†ææ¨¡å¼ï¼")
                    
                    st.session_state.comparison_results = None
                    st.info("é é¢å³å°‡åˆ·æ–°...")
                    # ä½¿ç”¨ st.experimental_rerun() æˆ– st.rerun() æ ¹æ“šæ‚¨çš„ Streamlit ç‰ˆæœ¬
                    st.rerun()

            except Exception as e:
                st.error(f"åœ¨ AI å­¸ç¿’éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
